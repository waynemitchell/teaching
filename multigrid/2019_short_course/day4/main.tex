\documentclass[18pt,xcolor=table]{beamer}

\input{./pres_style.tex}

%%%%%%%%%%%%%%%%%%%%%%%
% user-defined commands
%%%%%%%%%%%%%%%%%%%%%%%
\input{./macros.tex}%added macro definitions here

\usepackage{tikz}
\usepackage{tabularx}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{arrows,positioning} 

\usepackage{cancel}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[]{algorithm}
\usepackage{algpseudocode}
\captionsetup{compatibility=false}


\title[Multigrid]{Introduction to Multigrid Methods}
\subtitle{Day 4: Advanced Problems}
\author[Mitchell]{Wayne Mitchell}
\institute{\pgfuseimage{logo}\\Universit\"at Heidelberg\\Institut f\"ur Technische Informatik}
\date[]{\alert{}}


\begin{document}
\input{./slide_style.tex}

\DeclareRobustCommand{\Chi}{\raisebox{2pt}{$\chi$}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Slide
\begin{frame}{}
\begin{block}{Day 4 Goals}
\bit
\item Session 1:
\bit
\item Multigrid approaches for non-linear problems
\eit
\item Session 2:
\bit
\item Theoretical difficulties for non-symmetric problems
\item Graph problems as an example non-PDE application for multigrid
\eit
\item Session 3:
\bit
\item Discussion and hands-on examples
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}
\frametitle{\bf Outline:}
\framesubtitle{~~}
\tableofcontents
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

% Slide
\begin{frame}{Introduction}
\begin{block}{Advanced problems}
\bit
\item Previous lectures focused on multigrid for symmetric positive definite (SPD) problems resulting from discretization of elliptic PDEs
\item Today's lecture examines a few extensions to more advanced problems:
\bit
\item Non-linear
\item Non-symmetric
\item Non-PDE
\eit
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Non-linear problems}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Definition of linearity}
\bit
\item $A$ is linear if:
\bit
\item $A(\mathbf{u} + \mathbf{v}) = A(\mathbf{u}) + A(\mathbf{v})$, if $\mathbf{u},\mathbf{v}$ arbitrary vectors
\item $A(\alpha\mathbf{u}) = \alpha A(\mathbf{u})$, if $\alpha$ is a scalar
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Definition of linearity}
\bit
\item Consider $A = -\Delta$. Then,
\bit
\item $A(u + v) = -\Delta(u + v) = -\Delta u - \Delta v$
\item $A(\alpha u) -\Delta (\alpha u) = -\alpha \Delta u$
\eit
\item Now consider $A(u) = u^2$
\bit
\item $A(u + v) = (u + v)^2 \neq u^2 + v^2$
\item $A(\alpha u) = (\alpha u)^2 \neq \alpha u^2$
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Newton's method}
\bit
\item Newton's method is an iterative solution method for non-linear equations
\item Consider a non-linear equation in 1D, $A(\tilde{u}) = 0$
\item Given initial guess, $u$, and error, $e = \tilde{u} - u$, consider the Taylor expansion about $u$:
\eq{
   0 = A(\tilde{u}) = A(u + e) = A(u) + eA'(u) + \frac{s^2}{2}A''(\xi)
}
for $\xi$ between $u$ and $\tilde{u}$
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Newton's method}
\bit
\item Neglecting higher-order terms, solve for the correction, $e$:
\eq{
   0 &= A(u) + eA'(u) \\
   e &= -\frac{A(u)}{A'(u)}
}
\item Use approximate error to iteratively update the guess
\eq{
   u \leftarrow u - \frac{A(u)}{A'(u)}
}
\item The above iteration is Newton's method
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Newton's method}
\bit
\item Consider the $N$-dimensional non-linear system:
\eq{
   A(\mathbf{\tilde{u}}) 
   = 
   \begin{bmatrix}
   A_1(\tilde{u}_1,\tilde{u}_2,...,\tilde{u}_N) \\
   A_2(\tilde{u}_1,\tilde{u}_2,...,\tilde{u}_N) \\
   \vdots \\
   A_N(\tilde{u}_1,\tilde{u}_2,...,\tilde{u}_N)
   \end{bmatrix} 
   = 
   \begin{bmatrix}
   0 \\
   0 \\
   \vdots \\
   0
   \end{bmatrix} 
   =
   \mathbf{0}
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Newton's method}
\bit
\item Taylor expansion in $N$ dimensions about guess, $\mathbf{u}$, with error, $\mathbf{e}$:
\eq{
   \mathbf{0} = A(\mathbf{u} + \mathbf{e}) = A(\mathbf{u}) + J(\mathbf{u})\mathbf{e} + \text{higher-order terms}
}
where $J(\mathbf{u})$ is the Jacobian matrix $J$ evaluated at $\mathbf{u}$
\eq{
   J(\mathbf{u})
   = 
   \begin{bmatrix}
   \frac{\partial A_1(\mathbf{u})}{\partial u_1} & \frac{\partial A_1(\mathbf{u})}{\partial u_2} & \dots & \frac{\partial A_1(\mathbf{u})}{\partial u_N} \\
   \frac{\partial A_2(\mathbf{u})}{\partial u_1} & \frac{\partial A_2(\mathbf{u})}{\partial u_2} & \dots & \frac{\partial A_2(\mathbf{u})}{\partial u_N} \\
   \vdots \\
   \frac{\partial A_N(\mathbf{u})}{\partial u_1} & \frac{\partial A_N(\mathbf{u})}{\partial u_2} & \dots & \frac{\partial A_N(\mathbf{u})}{\partial u_N}
   \end{bmatrix}    
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Newton's method}
\bit
\item Newton's method for systems:
\eq{
   \mathbf{u} \leftarrow \mathbf{u} - (J(\mathbf{u}))^{-1}A(\mathbf{u})
}
\item Note: the non-linear problem has been reduced to iteratively solving a sequence of linear systems!
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Newton-Multigrid}
\bit
\item Obvious application of multigrid: solve $(J(u))^{-1}A(u)$ with multigrid
\item This approach is called Newton-Multigrid and can work well
\item We would like to apply multigrid principles directly to the non-linear problem
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Non-linear relaxation}
\bit
\item Need a relaxation method for the non-linear system, $A(\mathbf{u}) = \mathbf{f}$
\item Non-linear Gauss-Seidel: 
\bit
\item For $j = 1...N$:
\item Solve the $j^{th}$ equation for the $j^{th}$ component of the solution vector:
\eq{
   A_j(\mathbf{u}+s\mathbf{\epsilon}_j) = f_j
}
where $\mathbf{\epsilon}_j$ is the $j^{th}$ canonical basis vector
\item Can use scalar Newton's method for the solve above
\item Update solution vector: $\mathbf{u} \leftarrow \mathbf{u} + s\mathbf{\epsilon}_j$
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Non-linear coarse-grid correction}
\bit
\item Coarse-grid correction is based on solving the residual equation
\item In the linear case, $A\mathbf{e} = A(\mathbf{\tilde{u}} - \mathbf{u}) = \mathbf{f} - A\mathbf{u}$
\item Not so in the non-linear case!
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Non-linear coarse-grid correction}
\bit
\item Still want to solve the residual equation for a correction, $\mathbf{e}$:
\eq{
   \mathbf{f} - A(\mathbf{u}) = \mathbf{r} \\
   A(\mathbf{u} + \mathbf{e}) - A(\mathbf{u}) = \mathbf{r}
}
\item Furthermore, want to solve for the correction on a coarse grid:
\eq{
   A^c(\mathbf{u}^c + \mathbf{e}^c) - A^c(\mathbf{u})^c = \mathbf{r}^c 
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Non-linear coarse-grid correction}
\bit
\item Can restrict the residual $\mathbf{r}^c$ from the fine grid as usual:
\eq{
   \mathbf{r}^c = R\mathbf{r} = R(\mathbf{f} - A(\mathbf{u}))
}
\item Similarly, restrict the current solution iterate, $\mathbf{u}$:
\eq{
   \mathbf{u}^c = R\mathbf{u}
}
\eit
\end{block}
\end{frame}


% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Non-linear coarse-grid correction}
\bit
\item Substitute these into the coarse-grid residual equation:
\eq{
   A^c(R\mathbf{u} + \mathbf{e}^c) - A^c(R\mathbf{u}) = R\mathbf{r} \\
   A^c(\mathbf{\tilde{u}^c}) = A^c(R\mathbf{u}) + R\mathbf{r} 
}
\item Coarse-grid correction:
\bit
\item Solve for $\mathbf{\tilde{u}^c}$: 
\eq{
   A^c(\mathbf{\tilde{u}^c}) = A^c(R\mathbf{u}) + R(\mathbf{f} - A(\mathbf{u})) 
}
\item Get the coarse-grid correction:
\eq{
   \mathbf{e}^c = \mathbf{\tilde{u}}^c - R\mathbf{u}
}
\item Interpolate and add the correction:
\eq{
   \mathbf{u} \leftarrow \mathbf{u} + P\mathbf{e}^c
}
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Interpolation, restriction, and coarse-grid operator}
\bit
\item Often the same linear interpolation and full-weighting restriction used in the linear case are sufficient (can also use higher-order geometric interpolation)
\item Coarse-grid operator is usually obtained through rediscretization on the coarse grid
\item Can also sometimes form $A^c(\mathbf{u}^c) = RA(\mathbf{u})P$
\eit 
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Full approximation scheme (FAS)}
\bit
\item Now have all the pieces for a multigrid cycle
\begin{algorithm}[H]
\caption{Full approximation scheme (FAS) two-grid cycle}
\begin{algorithmic}
\State Set $\mathbf{u}$ initial guess
\State Do non-linear relaxation on $A(\mathbf{u}) = \mathbf{f}$
\State Calculate residual $\mathbf{r} = \mathbf{f} - A(\mathbf{u})$
\State Restrict residual $\mathbf{r}^c = R\mathbf{r}$
\State Restrict approximate solution $\mathbf{u}^c = R\mathbf{u}$
\State Solve on the coarse grid $A^c(\mathbf{\tilde{u}}^c) = A^c(\mathbf{u}^c) + \mathbf{r}^c$
\State Get the coarse-grid correction $\mathbf{e}^c = \mathbf{\tilde{u}^c} - \mathbf{u}^c$
\State Interpolate coarse-grid correction $\mathbf{u} = \mathbf{u} + P\mathbf{e}^c$
\State Do non-linear relaxation on $A(\mathbf{u}) = \mathbf{f}$
\end{algorithmic}
\end{algorithm}
\eit
\end{block}
\end{frame}


% Slide
\begin{frame}{Non-linear problems}
\begin{block}{Full approximation scheme (FAS)}
\bit
\item Similar extension to multilevel as in the linear case: V-cycles, W-cycles, FMG
\item Note that if $A$ is linear, FAS reduces to regular multigrid cycling
\item FAS is a fixed point iteration 
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{$\tau$ correction}
\bit
\item A different way to write the coarse-grid equation:
\eq{
   A^c(\mathbf{\tilde{u}}^c) &= A^c(\mathbf{u}^c) + \mathbf{r}^c \\
   A^c(\mathbf{\tilde{u}}^c) &= A^c(R\mathbf{u}) + R(\mathbf{f} - A(\mathbf{u})) \\
   A^c(\mathbf{\tilde{u}}^c) &= R\mathbf{f} + (A^c(R\mathbf{u}) - RA(\mathbf{u})) 
}
\item Let $R\mathbf{f} = \mathbf{f}^cc$ and $\tau = A^c(R\mathbf{u}) - RA(\mathbf{u})$
\item Then the coare-grid equation is:
\eq{
   A^c(\mathbf{\tilde{u}}^c) = \mathbf{f}^c + \tau
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{$\tau$ correction}
\bit
\item Thus the coarse grid equation is not simply $A^c(\mathbf{\tilde{u}}^c) = \mathbf{f}^c$, as one might expect
\item The $\tau$ correction is a modification of the coarse-grid equation to enhance approximation properties of the coarse-grid solution
\item The $\tau$ correction yields coarse-grid solution $\mathbf{\tilde{u}}^c$ that has \emph{accuracy} comparable to the fine-grid $\mathbf{\tilde{u}}$, but at the \emph{resolution} of the coarse grid
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-linear problems}
\begin{block}{FMG and the basin of attraction}
\bit
\item In general, non-linear solvers need a good initial guess in order to convergece
\item An initial guess that is good enough to yield convergence is said to be in the basin of attraction
\item Running FAS in an FMG cycle is usually an effective way to generate a good fine-grid initial guess
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Non-symmetric problems}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{PDE examples of non-symmetric problems}
\bit
\item Advection-diffusion-reaction:
\eq{
   -\nabla\cdot K \nabla u + \mathbf{b}\cdot\nabla u + \sigma u = f
}
\item Advection term, $\mathbf{b}\cdot\nabla u$, is non-symmetric
\item Discretization yields non-symmetric matrices
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{Issues with non-symmetric problems}
\bit
\item Non-symmetric: $A\neq A^T$
\item Many useful properties are no longer available:
\bit
\item There is no $A$-norm (or inner product)
\item Eigenvalues of $A$ are no longer positive real numbers
\item Eigenvectors are no longer an orthonormal basis
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{Issues with non-symmetric problems}
\bit
\item Recall the coarse-grid correction error propagation matrix:
\eq{
   \mathbf{e} \leftarrow (I - P(RAP)^{-1}RA)\mathbf{e} = \Pi\mathbf{e}
}
\item In the symmetric case, $\Pi$ is an $A$-orthogonal projection, implying $||\Pi||_A=1$
\item Coarse-grid correction can't "blow up" the error in the $A$-norm
\item Not so in the non-symmetric case! 
\item There is no $A$-norm, and generally $||\Pi||>1$ in any given norm
\item Need to retain $||\Pi|| = O(1)$ independent of grid size to get a "stable" coarse-grid correction
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{Simple approach}
\bit
\item Simplest approach is to apply AMG as is
\item Coarsen and build interpolation as usual, and set $R = P^T$, $A^c = P^TAP$
\item Choice of $R = P^T$ is somewhat arbitrary in this case
\bit
\item No $A$-norm, so no notion of optimal $A$-norm correction
\item $A$ is non-symmetric, so $P^TAP$ is also non-symmetric
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{Simple approach}
\bit
\item Classical AMG works well for diffusion dominated problems and for simple grid-aligned advection
\item Strong connections (and thus coarsening) along characteristics
\item More complex flows (recirculating flows) are problematic
\item Classical AMG is generally not robust for non-symmetric problems
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{Tailoring AMG to non-symmetric problems}
\bit
\item Southworth, Manteuffel, and Ruge. Nonsymmetric Algebraic Multigrid Based on Local Approximate Ideal Restriction ($l$AIR). SIAM J. Sci. Comp. 2018.
\item Main ideas: 
\bit
\item Do not choose $R = P^T$
\item Focus on building a good restriction operator (instead of interpolation)
\item Coarse-grid correction tries to eliminate error at C-points
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{Ideal interpolation and restriction}
\bit
\item Given matrix $A$ and a C/F splitting, consider the following block form of $A$:
\eq{
   A = \begin{bmatrix}
   A_{ff} & A_{fc} \\
   A_{cf} & A_{cc}
   \end{bmatrix}
}
\item Let interpolation and restriction take the following block forms:
\eq{
   P = \begin{bmatrix}
   W \\
   I
   \end{bmatrix}
   & &
   R = \begin{bmatrix}
   Z & I 
   \end{bmatrix}  
}
\item Identity blocks, $I$, are over the C-points
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{Ideal interpolation and restriction}
\bit
\item Basic multigrid principle: relaxation effectively reduces F-point residuals
\eq{
   \mathbf{r}_f = A_{ff}\mathbf{e}_f + A_{fc}\mathbf{e}_c \approx \mathbf{0} \\
   \Rightarrow \mathbf{e}_f = -A_{ff}^{-1}A_{fc}\mathbf{e}_c
}
\item The "ideal" interpolation operator exactly represents such error (i.e. places it in the range of interpolation):
\eq{
   P_{\text{ideal}} = \begin{bmatrix}
   -A_{ff}^{-1}A_{fc} \\
   I
   \end{bmatrix}
}
\item Ideal interpolation is never obtained in practice
\item Guides development of AMG algorithms that somehow attempt sparse approximation of ideal interpolation
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Non-symmetric problems}
\begin{block}{Ideal interpolation and restriction}
\bit
\item Ideal interpolation focuses on eliminating residuals at F-points
\item Ideal restriction focuses on eliminating error at C-points
\eq{
   R_{\text{ideal}} = \begin{bmatrix}
   -A_{cf}A_{ff}^{-1} & I 
   \end{bmatrix}  
}
\item Again, can design AMG algorithms based on sparse approximation of ideal restriction
\item Very effective when combined with effective F-relaxation
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Graph problems}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Graphs}
\bit
\item A graph is defined by a collection of nodes, edges, and weights: $G = (\mathcal{N},\mathcal{E},W)$
\item An edge, $e_{i,j}\in\mathcal{E}$, is a connection between two nodes, $i,j\in\mathcal{N}$ and may have an assigned weight, $w_{i,j}\in W$.
\item A graph with no self-loops has no edges $e_{i,i}$
\item In an undirected graph, if there is a connection $e_{i,j}$ with weight $w_{i,j}$, then there is also an edge $e_{j,i}$ with weight $w_{j,i} = w_{i,j}$
\item In an unweighted graph, $w_{i,j} = 1$ for all $i,j$
\item A graph is connected if there is some path connecting all pairs of nodes
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Graph applications}
\bit
\item PDEs on graphs
\item Electrical networks/power grids
\item Machine learning regression and classification problems
\item Social networks
\item Internet web page graphs and page rank
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Graph Laplacians}
\bit
\item The graph Laplacian, $A$, is a matrix representation of a graph with entries
\eq{
   a_{i,j} = \begin{cases}
   \sum_k w_{i,k}\,, & j = i \\
   w_{i,j}\,, & e_{i,j}\in\mathcal{E} \\
   0\,, & \text{else} 
   \end{cases}
}
\item Assume $G$ is an undirected graph with all positive weights and no self-loops
\item Then $A$ resembles a discrete Laplacian operator 
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Graph Laplacians vs. discretized PDEs}
\bit
\item Structured grid: regular stencil patterns, easy geometric coarsening/interpolation (GMG)
\item Unstructured grid: still regular stencil patterns, need algebraic coarsening/interpolation (AMG)
\item Arbitrary graph: no geometry and arbitrary connectivity/stencils (need special AMG)
\eit
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/structuredGrid}
\includegraphics[width=0.3\textwidth]{../figures/unstructuredGrid}
\includegraphics[width=0.3\textwidth]{../figures/graph}
\end{center}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Lean algebraic multigrid (LAMG)}
\bit
\item Livne and Brandt. Lean algebraic multigrid (LAMG): fast graph Laplacian linear solver. SIAM J. Sci. Comp. 2012.
\item AMG algorithm tailored to solving graph Laplacians for undirected graphs
\item "Lean" because it utilizes simple components designed to optimize cycle efficiency
\bit
\item Gauss-Seidel relaxation
\item Two different coarsening procedures: low-degree elimination and aggregation
\item Piecewise constant interpolation
\item Galerkin coarse-grid operators, $A^c = P^TAP$, are also graph Laplacians
\item 
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{LAMG coarsening: low-degree elimination}
\bit
\item Low-degree elimination attempts to remove many nodes while adding few edges
\item Removed nodes form an independent set with degree $\leq 4$
\item When a node is eliminated, its neighbors are connected
\item Elimination can be repeated until there are no more (or few) low-degree nodes
\eit
\end{block}
\begin{center}
\includegraphics[width=0.4\textwidth]{../figures/lowDegreeElim}
\end{center}
\tiny{Figure credit: Livne and Brandt.}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{LAMG coarsening: aggregation}
\bit
\item Aggregate nodes using "affinity," a modified strength of connection measure based on smoothed test vectors
\item Generate test vectors via a few Gauss-Seidel iterations on $A\mathbf{u} = \mathbf{0}$ with random initial guess
\item Two nodes $i$ and $j$ are highly correlated (and should be aggregated) if $u_i\approx u_j$ for all test vectors, $\mathbf{u}$
\item Approach is similar to adaptive AMG techniques
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{LAMG interpolation}
\bit
\item Interpolation, $P$, is simply piecewise constant interpolation over aggregates
\item This is basically an unsmoothed aggregation AMG approach
\item Sparse $P$ limits fill in for Galerkin coarse-grid operators, $A^c = P^TAP$
\item Reduced interpolation accuracy is overcome through "energy-corrected coarsening" (a modification of the restricted)
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Extensions to LAMG: the signed case}
\bit
\item LAMG was designed for unsigned (all positive edge weights) and undirected (symmetric edges) graphs
\item Signed undirected graphs may have negative edge weights
\item Graph Laplacian has some positive off-diagonals 
\item Diagonal of the graph Laplacian is the total weight, $a_{i,i} = \sum_k |w_{i,k}|$, so $A$ is still diagonally dominant
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Extensions to LAMG: the signed case}
\bit
\item Fox, Manteuffel, and Sanders. Numerical Methods for Gremban's Expansion of Signed Graphs. SIAM J. Sci. Comp. 2017.
\item Convert a signed graph Laplacian into an unsigned Laplacian and apply LAMG
\item Gremban's expansion: If $S$ is diagonally dominant with positive diagonal, then $S$ may be decomposed as $S = M + P$, where $M$ is a diagonally dominant Z-matrix and $P$ has non-negative entries and zero diagonal. Then the Gremban expansion matrix, $G$, defined by
\eq{
   G = \begin{bmatrix}
   M & -P \\
   -P & M
   \end{bmatrix}
}
is a diagonally dominant Z-matrix.
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Extensions to LAMG: the signed case}
\bit
\item If $S$ is a signed graph Laplacian, then the resulting $G$ is an unsigned graph Laplacian
\item Solution to $S\mathbf{x} = \mathbf{b}$ can be obtained from the solution to $G\mathbf{w} = \mathbf{z}$
\eq{
   G\mathbf{w} = \begin{bmatrix}
   M & -P \\
   -P & M
   \end{bmatrix}\begin{bmatrix}
   \mathbf{x} \\
   \mathbf{x}
   \end{bmatrix}
   = \begin{bmatrix}
   S\mathbf{x} \\
   -S\mathbf{x}
   \end{bmatrix}
   = \begin{bmatrix}
   \mathbf{b} \\
   -\mathbf{b}
   \end{bmatrix} = \mathbf{z}
}
\item Can also relate the eigenvectors and singular vectors of $S$ and $G$
\item Can apply LAMG successfully to $G$ to solve signed graph problems!
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Graph problems}
\begin{block}{Extensions to LAMG: the undirected case}
\bit
\item Fox and Manteuffel. Algebraic multigrid for directed graph Laplacian linear systems (NS-LAMG). Numer. Lin. Alg. Appl. 2018.
\item Undirected graph Laplacians are no longer symmetric
\item Modification of low-degree elimination for the non-symmetric case
\item Modified algorithm to find appropriate test vectors for defining interpolation
\item Coarse grid operators, $A_c = RAP$, where $R\neq P^T$
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

