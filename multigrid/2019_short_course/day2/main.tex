\documentclass[18pt,xcolor=table]{beamer}

\input{./pres_style.tex}

%%%%%%%%%%%%%%%%%%%%%%%
% user-defined commands
%%%%%%%%%%%%%%%%%%%%%%%
\input{./macros.tex}%added macro definitions here

\usepackage{tikz}
\usepackage{tabularx}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{arrows,positioning} 

\usepackage{cancel}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[]{algorithm}
\usepackage{algpseudocode}
\captionsetup{compatibility=false}


\title[Multigrid]{Introduction to Multigrid Methods}
\subtitle{Day 2: Geometric Multigrid}
\author[Mitchell]{Wayne Mitchell}
\institute{\pgfuseimage{logo}\\Universit\"at Heidelberg\\Institut f\"ur Technische Informatik}
\date[]{\alert{}}


\begin{document}
\input{./slide_style.tex}

\DeclareRobustCommand{\Chi}{\raisebox{2pt}{$\chi$}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{\bf Outline:}
\framesubtitle{~~}
\tableofcontents
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}

% Slide
\begin{frame}{Introduction}
\begin{block}{Day 2 Goals}
\bit
\item Basic theoretical motivations for multigrid
\item Define the basic components of multigrid: relaxation, interpolation, and restriction
\item Outline geometric multigrid on a model problem
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}
\begin{block}{Acknowledgements}
\bit
\item These slides are based on previous tutorials by Steve McCormick, Van Henson, Rob Falgout, Irad Yavneh, David Moulton.
\item https://github.com/copper-multigrid-conference
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Introduction}
\begin{block}{Resources}
\bit
\item A Multigrid Tutorial. Briggs, Henson, McCormick.
\item Multigrid. Trottenberg, Oosterlee, Sch\"uller.
\item Matrix Computations. Golub, Van Loan.
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Basic iterative methods on a model problem}


% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Moving from basic iterative methods to multigrid}
\bit
\item Focus on a model elliptic PDE problem
\item Examine the behavior of basic iterative methods on this problem
\item Use that behavior to motivate the move towards multigrid
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Model problem: Poisson}
\bit
\item Classic model problem is a simple Poisson problem with zero Dirichlet boundary conditions:
\eq{
\Delta u &= f, & \Omega \\
u &= 0, & \partial \Omega
}
\item Discretizing with finite differences on a regular 1D mesh:
\eit
\eq{
&\frac{-u_{i-1} + 2u_i - u_{i+1}}{h^2} = f_i, & i = 1,2,..., N-1 \\
&u_0 = u_N = 0
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Model problem: Poisson}
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/1DFDPoisson}
\end{center}
\eq{
\frac{1}{h^2}\begin{bmatrix}
2 & -1 & & & & & & \\
-1 & 2 & -1 & & & & & \\
& -1 & 2 & - 1 & & & & \\
&  & \ddots & \ddots & \ddots & & & \\
& & & & & & & \\
& & & & & -1 & 2 & -1 \\
& & & & & & -1 & 2 \\
\end{bmatrix}
\begin{bmatrix}
u_1 \\
u_2 \\
\\
\vdots \\
\\
\\
u_{N-1} \\
\end{bmatrix}
=
\begin{bmatrix}
f_1 \\
f_2 \\
\\
\vdots \\
\\
\\
f_{N-1} \\
\end{bmatrix}
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Review of eigenvalues and eigenvectors}
\bit
\item Eigenvalues, $\lambda_k$, and eigenvectors, $\mathbf{v}_k$, of a matrix, $A$, are defined by
\eq{
   A\mathbf{v}_k = \lambda_k \mathbf{v}_k
}
\item Evals and evecs can be a way to think about ``action" of an operator: rotation and scaling
\item Important in many applications from physics and engineering
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Review of eigenvalues and eigenvectors}
\bit
\item If $A$ is symmetric positive definite (SPD), then eigenvalues are real and positive and eigenvectors form an orthonormal basis for $\mathcal{R}^{N-1}$
\item Thus, any vector, $\mathbf{x}\in\mathcal{R}^{N-1}$ can be decomposed as 
\eq{
   \mathbf{x} = \sum_{k=1}^{N-1} \langle \mathbf{x}, \mathbf{v}_k \rangle \mathbf{v}_k 
}
\item We can study behavior of iterative methods by considering their effect on different eigenvectors
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Evals and evecs of the model problem}
\bit
\item $A = tridiag(-1,2,-1)$, then
\eq{
   \lambda_k &= 4\sin^2\left(\frac{k\pi}{2N}\right), &k = 1,...,N-1 \\
   v_k,j &= \sin\left(\frac{jk\pi}{N}\right), &j,k = 1,...,N-1 
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Jacobi on the model problem}
\bit
\item Recall the Jacobi iteration
\eq{
   \mathbf{u} \leftarrow D^{-1}(\mathbf{f} + (L+U)\mathbf{u})
}
\item Jacobi is a matrix splitting iteration with error propagation matrix
\eq{
   E &= D^{-1}(L+U) \\
   &= I - D^{-1}A
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Jacobi on the model problem}
\bit
\item $E$ and $A$ have the same evecs, $\mathbf{v}_k$
\item The evals, $\tilde\lambda_k$, of $E$ are related to those of $A$ (recall $D = 2I$)
\eq{
   \tilde\lambda_k &= 1 - \frac{1}{2}\lambda_k \\
   &= 1 - 2\sin^2\left(\frac{k\pi}{2N}\right)
}
\eit
\end{block}
\end{frame}


% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Error reduction for Jacobi}
\bit
\item Given initial error, $\mathbf{e}^{(0)}$, error on the $i^th$ iteration is 
\eq{
   \mathbf{e}^{(i)} &= E^i\mathbf{e}^{(0)} \\
   &= E^i\left(\sum_{k=1}^{N-1} \langle \mathbf{e}^{(0)}, \mathbf{v}_k \rangle \mathbf{v}_k\right) \\
   &= \sum_{k=1}^{N-1} \tilde\lambda_k^i \langle \mathbf{e}^{(0)}, \mathbf{v}_k \rangle \mathbf{v}_k
}
\item So the $k^{th}$ ``error mode" is reduced by $\tilde\lambda_k$ on each iteration
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Error reduction for Jacobi}
\bit
\item Error modes associated with large and small evals are damped very slowly
\eq{
   \tilde\lambda_k = 1 - 2\sin^2\left(\frac{k\pi}{2N}\right)
}
\eit
\end{block}
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/jacobiModeDamping}
\end{center}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Weighted Jacobi}
\bit
\item In practice, Jacobi is usually modified with a weighting parameter, $\omega$
\eq{
   \mathbf{u} \leftarrow (1 - \omega)\mathbf{u} + \omega D^{-1}(\mathbf{f} + (L+U)\mathbf{u})
}
\item The error propagation matrix in this case is
\eq{
   E &= I - \omega D^{-1}A
}
\item The associated evals are
\eq{
   \tilde\lambda_k &= 1 - 2\omega\sin^2\left(\frac{k\pi}{2N}\right)
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{center}
\begin{block}{Error reduction for Jacobi}
\bit
\item With appropriate $\omega$, can effectively damp modes associated with large $k$
\eq{
   \tilde\lambda_k = 1 - 2\omega\sin^2\left(\frac{k\pi}{2N}\right)
}
\eit
\end{block}
\includegraphics[width=0.6\textwidth]{../figures/weightedJacobiModeDamping}
\end{center}
\end{frame}

% Slide
\begin{frame}{Basic iterative methods on a model problem}
\begin{block}{Gauss-Seidel}
\bit
\item Gauss-Seidel exibits similar behavior
\item Evecs of error propagation, $E$, for Gauss-Seidel are not the same as the evecs of $A$
\item Gauss-Seidel also damps the evecs of $A$ associated with large evals
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Towards multigrid}

% Slide
\begin{frame}{Towards multigrid}
\begin{block}{Observations}
\bit
\item Weighted Jacobi and Gauss-Seidel are not good solvers on their own
\item They do a good job at damping certain error modes for the model problem
\item Specifically, they remove ``high-frequency" error (they damp the oscillatory evecs of $A$)
\item Call these ``smoothers" or ``relaxation methods"
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Towards multigrid}
\begin{block}{Observations}
\bit
\item Smooth modes are representable on a coarser grid
\item Furthermore, they are relatively more oscillatory on that grid 
\eit
\end{block}
\only<1>{
\begin{center}
\includegraphics[width=0.6\textwidth]{../figures/smoothMode}
\end{center}
}
\only<2>{
\begin{center}
\includegraphics[width=0.6\textwidth]{../figures/modeCoarse}
\end{center}
}
\end{frame}

% Slide
\begin{frame}{Towards multigrid}
\begin{block}{Observations}
\bit
\item Recall that relaxation makes the error, $\mathbf{e}$, smooth (even if the solution, $\mathbf{u}$, is oscillatory)
\item The error satisfies the residual equation
\eq{
   A\mathbf{e} = \mathbf{r}
}
\item Idea: can use relaxation on a coarse grid to effectively solve the residual equation! 
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Towards multigrid}
\begin{block}{Coarse-grid correction}
\bit
\item Relax on $A^f\mathbf{u}^f = \mathbf{f}^f$ to obtain approximate fine-grid solution
\item Error, $\mathbf{e}^f = \mathbf{\tilde u} - \mathbf{u}^f$, is smooth
\item Calculate the residual $\mathbf{r}^f = \mathbf{f}^f - A^f\mathbf{u}^f$
\item Relax on $A^c\mathbf{e}^c = \mathbf{r}^c$ to obtain a coarse-grid correction
\item Correct on the fine grid $\mathbf{u}^f \leftarrow \mathbf{u}^f + \mathbf{e}^f$
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Towards multigrid}
\begin{block}{Remaining questions}
\bit
\item How to define the coarse grid?
\item How to move between grid levels?
\item How to go from two-grid to multigrid?
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Components of multigrid}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Components of multigrid}
\bit
\item Hierarchy of grids and associated problems
\item Relaxation methods to apply to problems on each grid level
\item Interpolation from coarse to fine grids
\item Restriction from fine to coarse grids
\item Cycle structure
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Coarse grids}
\bit
\item Rediscretize the PDE with half the step size
\eit
\end{block}
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/coarse1DFDPoisson}
\end{center}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Interpolation (prolongation)}
\bit
\item Linear interpolation
\item Identity at C-points
\item Average of neighbors at F-points
\eq{
   e^f_i = \begin{cases}
   e^c_{i/2}, &i \,\,\text{even} \\
   \frac{1}{2}(e^c_{(i-1)/2} + e^c_{(i+1)/2}, &i \,\,\text{odd}
   \end{cases}
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Interpolation (prolongation)}
\bit
\item Linear interpolation accurately reproduces smooth fine-grid error from a coarse representation
\eit
\end{block}
\only<1>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/coarseError}
\end{center}
}
\only<2>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/coarseCorrectionSmooth}
\end{center}
}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Interpolation (prolongation)}
\bit
\item If the fine-grid error is oscillatory, linear interpolation from the coarse grid is not so accurate
\eit
\end{block}
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/coarseCorrectionOscillatory}
\end{center}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Interpolation (prolongation)}
\bit
\item Matrix form of interpolation, $P\in\mathcal{R}^{(N-1)\times(N/2-1)}$
\eit
\eq{
   \begin{bmatrix}
   1/2 & & & \\
   1 & & & \\
   1/2 & 1/2 & & \\
    & 1 & \ddots & \\
    & \ddots & & \\
    &  & 1/2 & 1/2 \\
    &  & & 1 \\
    &  & & 1/2 \\
   \end{bmatrix}
   \begin{bmatrix}
   e^c_1 \\
   e^c_2 \\
   \vdots \\
   e^c_{N/2-1}
   \end{bmatrix}
   =
   \begin{bmatrix}
   e^f_1 \\
   e^f_2 \\
   \\
   \vdots \\
   \\
   e^f_{N-1}
   \end{bmatrix}
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Restriction}
\bit
\item Restriction by injection: C-points retain their value, F-points do not contribute
\eit
\eq{
   r^c_i = r^f_{2i}
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Restriction}
\bit
\item Restriction by injection: C-points retain their value, F-points do not contribute
\eit
\end{block}
\only<1>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/fineResidual}
\end{center}
}
\only<2>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/injectedResidual}
\end{center}
}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Restriction}
\bit
\item Matrix form of injection restriction, $R\in\mathcal{R}^{(N/2-1)\times(N-1)}$
\eit
\eq{
   \begin{bmatrix}
    0 & 1 & 0& & & & \\
    & & 0 & 1 & 0 & & \\
    & & & \ddots & \ddots & & \\
    & & & & & & \\
    & & & & 0 & 1 & 0\\
   \end{bmatrix}
   \begin{bmatrix}
   r^f_1 \\
   r^f_2 \\
   \\
   \vdots \\
   \\
   r^f_{N-1}
   \end{bmatrix}
   =
   \begin{bmatrix}
   r^c_1 \\
   r^c_2 \\
   \vdots \\
   r^c_{N/2-1}
   \end{bmatrix}
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Restriction}
\bit
\item Restriction by full-weighting: weighted average of C-points with their neighboring F-points
\eit
\eq{
   r^c_i = \frac{1}{4}r^f_{2i-1} + \frac{1}{2}r^f_{2i} + \frac{1}{4}r^f_{2i+1}
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Restriction}
\bit
\item Restriction by full-weighting: weighted average of C-points with their neighboring F-points
\eit
\end{block}
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/fullWeightingResidual}
\end{center}
\end{frame}


% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Restriction}
\bit
\item Matrix form of injection restriction, $R\in\mathcal{R}^{(N/2-1)\times(N-1)}$
\eit
\eq{
   \begin{bmatrix}
    1/4 & 1/2 & 1/4 & & & & \\
    & & 1/4 & 1/2 & 1/4 & & \\
    & & & \ddots & \ddots & & \\
    & & & & & & \\
    & & & & 1/4 & 1/2 & 1/4 \\
   \end{bmatrix}
   \begin{bmatrix}
   r^f_1 \\
   r^f_2 \\
   \\
   \vdots \\
   \\
   r^f_{N-1}
   \end{bmatrix}
   =
   \begin{bmatrix}
   r^c_1 \\
   r^c_2 \\
   \vdots \\
   r^c_{N/2-1}
   \end{bmatrix}
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Restriction}
\bit
\item Note that with full-weighting, $R = cP^T$
\item This relationship between interpolation and restriction is enforced in many multigrid hierarchies and yields nice properties
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{Two-grid cycle}
\begin{algorithm}[H]
\caption{Two-grid cycle}
\begin{algorithmic}
\State Set $\mathbf{u}$ initial guess
\State Relax on $A^f\mathbf{u}^f = \mathbf{f}^f$
\State Calculate residual $\mathbf{r}^f = \mathbf{f}^f - A^f\mathbf{u}^f$
\State Restrict residual $\mathbf{r}^c = R\mathbf{r}^f$
\State Solve on the coarse grid $A^c\mathbf{e}^c = \mathbf{r}^c$
\State Interpolate coarse-grid correction $\mathbf{u}^f = \mathbf{u}^f + P\mathbf{e}^c$
\State Relax again on $A^f\mathbf{u}^f = \mathbf{f}^f$
\end{algorithmic}
\end{algorithm}
\end{block}
\end{frame}













% Slide
\begin{frame}{Components of multigrid}
\begin{block}{}
\bit
\item 
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Components of multigrid}
\begin{block}{}
\bit
\item 
\eit
\end{block}
\end{frame}

% TODO: HEY! Mention the scaling for restriction. How does this relate to the h scaling and rediscretization?
% TODO: Note that A^c = RAP

% Define MG cycles
% Cost of MG: count up the operations to get compute cost
% Brief comment on discretization accuracy
% Save 2D examples for exercises
% Generally mention that we've developed all this stuff for Poisson, but you can do similar stuff for more general problems: Just have to figure out how to construct effective MG components for your problem. Forshadow AMG tries to do this as a black box.
% Use of MG as preconditioner for Krylov methods


% Maybe:
% 2D examples, anisotropic examples with line smoothing and semicoarsening



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

