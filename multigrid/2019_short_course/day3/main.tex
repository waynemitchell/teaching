\documentclass[18pt,xcolor=table]{beamer}

\input{./pres_style.tex}

%%%%%%%%%%%%%%%%%%%%%%%
% user-defined commands
%%%%%%%%%%%%%%%%%%%%%%%
\input{./macros.tex}%added macro definitions here

\usepackage{tikz}
\usepackage{tabularx}
\usetikzlibrary{decorations.markings}
\usetikzlibrary{arrows,positioning} 

\usepackage{cancel}
\usepackage{hyperref}
\usepackage{caption}
\usepackage{subcaption}
\usepackage[]{algorithm}
\usepackage{algpseudocode}
\captionsetup{compatibility=false}


\title[Multigrid]{Introduction to Multigrid Methods}
\subtitle{Day 3: Algebraic Multigrid (AMG)}
\author[Mitchell]{Wayne Mitchell}
\institute{\pgfuseimage{logo}\\Universit\"at Heidelberg\\Institut f\"ur Technische Informatik}
\date[]{\alert{}}


\begin{document}
\input{./slide_style.tex}

\DeclareRobustCommand{\Chi}{\raisebox{2pt}{$\chi$}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Slide
\begin{frame}{}
\begin{block}{Day 3 Goals}
\bit
\item Session 1:
\bit
\item Motivate and define aglebraic multigrid vs. geometric multigrid
\item Discuss algebraic smoothness and construction of AMG interpolation
\eit
\item Session 2:
\bit
\item AMG coarsening algorithm
\item Definition of coarse-grid operators and brief theory
\item Touch on smoothed aggregation AMG
\eit
\item Session 3:
\bit
\item Discussion and hands-on examples
\eit
\eit
\end{block}
\end{frame}

\begin{frame}
\frametitle{\bf Outline:}
\framesubtitle{~~}
\tableofcontents
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Motivation}

% Slide
\begin{frame}{Motivation}
\begin{block}{Benefits and limitations of geometric multigrid (GMG)}
\bit
\item Solution of many PDEs to discretization accuracy with optimal $O(N)$ cost
\item Multigrid components depend on geometry and discretization:
\bit
\item Coarsening
\item Interpolation and restriction
\item Definition of coarse-grid problems
\eit
\item Unclear how to proceed with unstructured meshes
\item Not applicable for problems with no underlying PDE or geometry
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Motivation}
\begin{block}{Goals of algebraic multigrid (AMG)}
\bit
\item Construct an effective multigrid hierarchy given only a matrix system $A\mathbf{u} = \mathbf{f}$
\item Agnostic to underlying PDE and discretization
\item More of a "black box" than GMG
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Motivation}
\begin{block}{GMG vs. AMG}
\bit
\item GMG:
\bit
\item Grids and interpolation dictated by discretization/geometry
\item Need to find appropriate smoother for the problem
\eit
\item AMG:
\bit
\item Relaxation method is usually fixed (Gauss-Seidel or similar)
\item Construct coarsenings and interpolation constructed based on matrix entries
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Motivation}
\begin{block}{Main approaches to AMG}
\bit
\item Use of simple pointwise smoothers (weighted Jacobi, Gauss-Seidel)
\item "Algebraic smoothness" rather than geometric smoothness
\item Strength of connection between points determined by matrix entries
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Motivation}
\begin{block}{Flavors of AMG}
\bit
\item "Classical" or Ruge-St\"uben AMG
\bit
\item Split grid into C- and F-points
\item Interpolation to F-points based on matrix connections to C-point neighbors
\eit
\item Smoothed aggregation (SA)
\bit
\item Fine-grid points grouped and treated as single points on coarse grid
\item Interpolation based on splitting smooth vectors over aggregates
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Motivation}
\begin{block}{Seminal papers}
\bit
\item Brandt, McCormick, and Ruge. Algebraic Multigrid (AMG) for Sparse Matrix Equations. Sparsity and Its Applications. 1984.
\item Brandt. Algebraic Multigrid Theory: The Symmetric Case. Applied Mathematics and Computation. 1986.
\item Ruge and St\"uben. Algebraic Multigrid (AMG). Multigrid Methods. 1987.
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Algebraic smoothness}

% Slide
\begin{frame}{Algebraic smoothness}
\begin{block}{Core idea of multigrid}
\bit
\item Relaxation and coarse-grid correction are complementary processes
\item Oscillatory/high-frequency/high-energy error damped by relaxation
\item Smooth/low-frequency/low-energy error damped by coarse-grid correction
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Algebraic smoothness}
\begin{block}{Smooth error}
\bit
\item Fundamental definition of smooth error, $\mathbf{e}$: error for which convergence of the smoother stalls
\eq{
   \mathbf{e}^{(k+1)} &= (I - M^{-1}A)\mathbf{e}^{(k)} \\
   ||\mathbf{e}^{(k+1)}|| &\approx ||\mathbf{e}^{(k)}||
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Algebraic smoothness}
\begin{block}{GMG on Poisson}
\bit
\item Recall GMG on the model Poisson problem
\item High-frequency evecs are damped by smoothing
\item Low-frequency evecs are damped by coarse-grid correction
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Algebraic smoothness}
\begin{block}{Algebraic characterization of smooth error}
\bit
\item How to characterize smooth error, $\mathbf{e}$, in an algebraic way?
\begin{enumerate}
   \item Small residual: $A\mathbf{e} \approx \mathbf{0}$
   \item Low energy: $||\mathbf{e}||_A = \langle \mathbf{e}, A\mathbf{e} \rangle \approx 0$
   \item Small eigenvalue: $A\mathbf{e} = \lambda\mathbf{e}$, with $\lambda \approx 0$
\end{enumerate}
\item Above characterizations are often related or equivalent
\item Different definitions for smooth error may be used to motivate different AMG algorithms
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Algebraic smoothness}
\begin{block}{Importance of smooth error in developing AMG components}
\bit
\item Interpolation must accurately reproduce smooth error
\item Coarse grid must be able to represent smooth error
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Interpolation}

% Slide
\begin{frame}{Interpolation}
\begin{block}{A first step toward algebraic interpolation}
\bit
\item Linear interpolation in GMG required geometric info
\item Want to define interpolation based only on $A$
\item Goal: accurately interpolate smooth error
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{A first step toward algebraic interpolation}
\bit
\item Algebraically smooth error has a small residual:
\eq{
   &A\mathbf{e} = \mathbf{r} \approx \mathbf{0} \\
   &\sum_j a_{i,j}e_j \approx 0, & \forall i \\
   &e_i \approx -\frac{1}{a_{i,i}} \sum_{j\neq i} a_{i,j}e_j, & \forall i
}
\item This implies that each component, $e_i$, can be written as a weighted average of its neighbors using entries in $A$
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Strength of connection}
\bit
\item One more concept before defining interpolation: strength of connection
\item Given some threshold, $0 < \theta \leq 1$, we say $e_i$ strongly depends on $e_j$ if
\eq{
   -a_{i,j} \geq \theta\max_{k\neq i}(-a_{i,k})
}
\item Note: assume $A$ is an M-matrix, i.e. $a_{i,j}\leq 0$ for $i\neq j$
\item Smooth error varies slowly along strong connections 
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item Assume a given C/F splitting
\item Let $C_i$ be the set of strongly connected C-points for point $i$
\item Goal is to construct interpolation, $P$, such that
\eq{
   (P\mathbf{e})_i = \begin{cases}
   e_i, & i\in C \\
   \sum_{j\in C_i} w_{i,j}e_j, & i \in F
   \end{cases}
}
\item Need to determine interpolation weights, $w_{i,j}$
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item Again start with the assumption that $A\mathbf{e} \approx \mathbf{0}$
\eq{
   a_{i,i} e_i = -\sum_{j\neq i} a_{i,j}e_j
}
\item Now break up the sum into different sets of points
\eq{
   a_{i,i} e_i = -\sum_{j\in C_i} a_{i,j}e_j - \sum_{j\in D^s_i} a_{i,j}e_j - \sum_{j\in D^w_i} a_{i,j}e_j
}
\item $D^s_i$ and $D^w_i$ are the strongly and weakly connected F-points respectively
\eit
\end{block}
\end{frame}

% NOTE: Can think of this as collapsing the stencil or infering the values at fine-grid points from the diagonal and connected C-points
% Collapsing the stencil: collapse F-F matrix entries to the diagonal or C-F connections
% Infering values: replace e_j (an F point) with e_i (the diagonal) or a weighted average of e_k's (C-poings)

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item The "stencil" of point $i$ includes the entire neighborhood of connected points
\eit
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencil}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item Strongly connected C-points form the interpolatory set
\item Rather than disregard F-F connections, collapse their values to the interpolation stencil
\eit
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencilCpts}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item Weakly connected F-points are added to the diagonal
\item Assume $e_i\approx e_j$ for $j\in D^w_i$
\eit
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencilWeakF}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\eq{
   a_{i,i} e_i = - \sum_{j\in C_i} a_{i,j}e_j - \sum_{j\in D^s_i} a_{i,j}e_j - \sum_{j\in D^w_i} a_{i,j}e_j \\
   (a_{i,i} + \sum_{j\in D^w_i} a_{i,j}) e_i = - \sum_{j\in C_i} a_{i,j}e_j - \sum_{j\in D^s_i} a_{i,j}e_j
}
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencilWeakF}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item Could do something similar with strong F-F connections
\item Practice has shown better results collapsing these values to the C-points
\eit
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencilStrongF}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item Can rewrite error at F-point, $j$, as a linear combination of C-points shared with $i$
\eit
\eq{
   e_j \approx \frac{\sum_{k \in C_i}a_{j,k}e_k}{\sum_{k \in C_i}a_{j,k}}
}
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencilStrongF}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\eq{
   &(a_{i,i} + \sum_{j\in D^w_i} a_{i,j}) e_i = - \sum_{j\in C_i} a_{i,j}e_j - \sum_{j\in D^s_i} a_{i,j}e_j \\
   &(a_{i,i} + \sum_{j\in D^w_i} a_{i,j}) e_i = - \sum_{j\in C_i} a_{i,j}e_j - \sum_{j\in D^s_i} a_{i,j}\frac{\sum_{k \in C_i}a_{j,k}e_k}{\sum_{k \in C_i}a_{j,k}}
}
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencilStrongF}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item Final interpolation formula
\eq{
   w_{i,j} = -\frac{a_{i,j} + \sum_{m\in D^s_i} \left( \frac{a_{i,m}a_{m,j}}{\sum_{k\in C_i} a_{m,k}} \right)}{a_{i,i} + \sum_{n \in D^w_i} a_{i,j}}
}
\eit
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencilCpts}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Classical interpolation formula}
\bit
\item Final interpolation formula
\eq{
   (P\mathbf{e})_i = \begin{cases}
   e_i, & i\in C \\
   \sum_{j\in C_i} w_{i,j}e_j, & i \in F
   \end{cases}
}
\eit
\end{block}
\begin{center}
\includegraphics[width=0.3\textwidth]{../figures/interpStencilCpts}
\end{center}
\end{frame}

% Slide
\begin{frame}{Interpolation}
\begin{block}{Notes on classical interpolation}
\bit
\item This is just one way of calculating interpolation weights
\item There are many other approaches
\item Active area of research for more difficult problems
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Coarsening}

% Slide
\begin{frame}{Coarsening}
\begin{block}{Requirements for the coarse grid}
\bit
\item Accurate approximate represention of smooth error from the fine grid
\item Accurate interpolation from coarse to fine grid
\item Significantly fewer points than the fine grid
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarsening}
\begin{block}{Coarse grid heuristics}
\bit
\item Let $S_i$ be the set of points that strongly influence $i$
\item Let $C_i$ be the interpolatory set for F-point, $i$
\item Then the coarse grid should attempt to ensure the following heuristics:
\begin{enumerate}
\item For each F-point, $i$, every point $j\in S_i$ is either in $C_i$ or strongly depends on at least one point in $C_i$
\item The set of C-points is a maximal subset such that no C-point strongly depends on another C-point.
\end{enumerate}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarsening}
\begin{block}{Coarse grid heuristics}
\bit
\item Heuristic 1 allows collapsing strong F-F connections to C-points in the interpolation stencil
\item Heuristic 2 controls the size of the coarse grid: large enough for good convergence but small enough to control computational work
\item Not always possible to enforce both heuristics
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarsening}
\begin{block}{Coloring scheme}
\bit
\item Classical AMG selects the coarse grid using a coloring scheme
\item Proceeds in two passes 
\item First, "high-quality" C-points are added following heuristic 2
\item Second, additional C-points are added to enforce heuristic 1
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarsening}
\begin{block}{Coloring scheme}
\bit
\item High-quality C-points strongly influence lots of F-points
\item Let $S^T_i$ be the set of points that $i$ strongly influences and $\lambda_i = |S^T_i|$
\item First pass proceeds as follows:
\begin{enumerate}
\item Select a point, $i$, with maximum $\lambda_i$ and mark as C-point
\item Mark points $j\in S^T_i$ as F-points
\item Increment $\lambda_k$ for unmarked points $k\in S_j$ for each $j\in S^T_i$
\item Repeat
\end{enumerate}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarsening}
\only<1>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening}
\end{center}}
\only<2>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-2}
\end{center}}
\only<3>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-3}
\end{center}}
\only<4>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-4}
\end{center}}
\only<5>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-5}
\end{center}}
\only<6>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-6}
\end{center}}
\only<7>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-7}
\end{center}}
\only<8>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-8}
\end{center}}
\only<9>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-9}
\end{center}}
\only<10>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-10}
\end{center}}
\only<11>{
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/amgCoarsening-11}
\end{center}}
\tiny{Slide credit: Luke Olson, Copper Mountain 2019 Algebraic Multigrid Tutorial}
\end{frame}

% Slide
\begin{frame}{Coarsening}
\begin{block}{Coloring scheme}
\bit
\item The above example is done after one pass
\item Both heuristics are satisfied
\item Coarsening produced is the same as geometric coarsening
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarsening}
\begin{block}{Coloring scheme}
\bit
\item Second pass switches some F-points to C-points to enforce heuristic 1
\item Not always used in practice
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarsening}
\begin{block}{Benefits of the coloring scheme}
\bit
\item Completely algebraic method for coarsening
\item Incorporates strength of connection
\item Automatically generates appropriate coarsenings that must be hand-selcted in GMG, e.g. semi-coarsening for anisotropic problems
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Coarse grid operators}

% Slide
\begin{frame}{Coarse grid operators}
\begin{block}{Coarse grid operators}
\bit
\item Coarsening and interpolation are defined
\item Still need restriction and coarse-grid operators
\item Typical choice of restriction: $R = P^T$
\item Galerkin coarse-grid operator: $A^c = RAP = P^TAP$
\item If $A = A^T$, then $A^c = P^TAP = (A^c)^T$
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarse grid operators}
\begin{block}{Optimality in $A$-norm}
\bit
\item Choosing $A^c = P^TAP$ provides optimal coarse-grid correction in the $A$-norm
\item Recall coarse-grid correction
\eit
\eq{
   \mathbf{u} \leftarrow \mathbf{u} + P(A^c)^{-1}R(\mathbf{f} - A\mathbf{u})
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarse grid operators}
\begin{block}{Optimality in $A$-norm}
\bit
\item Error propagator for coarse-grid correction
\eq{
   \mathbf{e} &\leftarrow \mathbf{e} - P(A^c)^{-1}RA\mathbf{e} \\
   \mathbf{e} &\leftarrow (I - P(P^TAP)^{-1}P^TA)\mathbf{e}
}
\item So coarse-grid correction applies $(I - P(P^TAP)^{-1}P^TA)$ to the error
\item Want $(P(P^TAP)^{-1}P^TA)\mathbf{e}$ to be a good approximation to $\mathbf{e}$
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarse grid operators}
\begin{block}{Optimality in $A$-norm}
\bit
\item Correction provided is in the range of interpolation, $Ran(P)$
\item The best correction in the $A$-norm is obtained by the minimization
\eq{
   \min_{\mathbf{v}\in Ran(P)} ||\mathbf{e} - \mathbf{v}||_A
}
\item The minimum is obtained by the orthogonal projection onto $Ran(P)$
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarse grid operators}
\begin{block}{Optimality in $A$-norm}
\bit
\item Can check that $\pi_A = (P(P^TAP)^{-1}P^TA)$ is an $A$-orthogonal projection
\bit
\item $\pi_A^2 = \pi_A$
\item $\langle \pi_A \mathbf{x}, A \mathbf{y} \rangle = \langle \mathbf{x}, A \pi_A\mathbf{y} \rangle$
\eit
\item Thus, the AMG coarse-grid correction is the best possible correction (in the $A$-norm) in the range of $P$
\eq{
   \min_{\mathbf{v}\in Ran(P)} ||\mathbf{e} - \mathbf{v}||_A = ||\mathbf{e} - (P(P^TAP)^{-1}P^TA)\mathbf{e}||_A
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Coarse grid operators}
\begin{block}{Coarse grid operator complexity}
\bit
\item Cost of GMG is straightforward to determine
\item Cost of AMG is less predictable
\bit
\item Coarse grids are not regular
\item Coarse-grid operators tend to fill in
\eit
\item Can define "complexity" of the hierarchy in a couple ways:
\bit
\item Grid complexity: number of points on all levels / fine grid
\item Operator complexity: number of matrix non-zeros on all levels / fine grid
\eit
\item Can try to control complexity, but generally only measureable after hierarchy construction
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Smoothed Aggregation (SA)}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\begin{block}{Smoothed aggregation (SA)}
\bit
\item A different approach to coarsening and building interpolation
\item Aggregate points rather than splitting into C- and F-points
\item Build interpolation directly based on known low-energy vectors
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\begin{block}{Aggregation}
\bit
\item Several variations on aggregation coarsening 
\item Final aggregates provide a disjoint covering of all points
\item Example algorithm:
\bit
\item Choose a desireable seed point (not adjacent to any existing aggregate)
\item Add all strongly connected neighbors of the seed point to the aggregate
\item Repeat until no seed points remain
\item Merge remaining single points into existing aggregates
\eit
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\only<1>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening1}
\end{center}}
\only<2>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening2}
\end{center}}
\only<3>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening3}
\end{center}}
\only<4>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening4}
\end{center}}
\only<5>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening5}
\end{center}}
\only<6>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening6}
\end{center}}
\only<7>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening7}
\end{center}}
\only<8>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening8}
\end{center}}
\only<9>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening9}
\end{center}}
\only<10>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening10}
\end{center}}
\only<11>{
\begin{center}
\includegraphics[width=0.5\textwidth]{../figures/saCoarsening11}
\end{center}
}
\end{frame}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\begin{block}{SA vs. Classical AMG}
\bit
\item Consider the \emph{aggregates} as coarse degrees of freedom
\item SA tends to coarseng more aggressively than C/F coloring
\eit
\end{block}
\begin{center}
\includegraphics[width=0.7\textwidth]{../figures/saCoarsening12}
\end{center}
\tiny{Slide credit: Luke Olson, Copper Mountain 2019 Algebraic Multigrid Tutorial}
\end{frame}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\begin{block}{Interpolation}
\bit
\item Low-energy (near null-space) vectors should be in the range of interpolation
\item SA takes a direct approach to this 
\item Assume we know a particular vector, $\mathbf{b}$, that we want in the range of interpolation
\item Start by constructing interpolation, $P$, such that 
\eit
\eq{
   P\mathbf{1}^c = \mathbf{b}
}
\end{block}
\end{frame}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\begin{block}{Interpolation}
\bit
\item Chop the vector, $\mathbf{b}$, over the aggregates
\item Resulting $P$ yields \emph{unsmoothed} aggregation interpolation
\eq{
   P\mathbf{1}^c = \begin{bmatrix}
   b_1 & 0 & 0 & ... \\
   b_2 & 0 & 0 & \\
   b_3 & 0 & 0 & \\
   0 & b_4 & 0 & \\
   0 & b_5 & 0 & \\
   0 & b_6 & 0 & \\
   0 & 0 & b_7 & \\
   0 & 0 & b_8 & \\
   \vdots & & & 
   \end{bmatrix}\begin{bmatrix}
   1 \\
   1 \\
   \vdots \\
   1
   \end{bmatrix} = \begin{bmatrix}
   b_1 \\
   b_2 \\
   b_3 \\
   \vdots \\
   \end{bmatrix} = \mathbf{b}
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\begin{block}{Interpolation}
\bit
\item To achieve \emph{smoothed} aggregation, improve $P$ by smoothing the columns
\item Apply relaxation (e.g. weighted Jacobi) to columns of $P$
\item $P_i$ the $i^{th}$ column of $P$, then do $P_i \leftarrow P_i - \omega D^{-1}AP_i$
\item Expands support of columns of $P$ beyond aggregates (columns now overlap)
\item "Mixes" more low-energy modes into the range of interpolation
\item For Poisson, $\mathbf{b} = \mathbf{1}$ is a good choice
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\begin{block}{Interpolation}
\bit
\item If several near null-space vectors are known (e.g. the rigid body modes in elasticity), SA can accomodate all of them!
\item If $\mathbf{b}_1,\mathbf{b}_2,\mathbf{b}_3$ are all target vectors, then tentative prolongation is
\eq{
   P\mathbf{1}^c = \begin{bmatrix}
   b_{1,1} & 0 & 0 & ... \\
   b_{1,2} & 0 & 0 & \\
   b_{1,3} & 0 & 0 & \\
   0 & b_{4,1} & 0 & \\
   0 & b_{5,1} & 0 & \\
   0 & b_{6,1} & 0 & \\
   0 & 0 & b_{7,1} & \\
   0 & 0 & b_{8,1} & \\
   \vdots & & & 
   \end{bmatrix}\begin{bmatrix}
   1 \\
   1 \\
   \vdots \\
   1
   \end{bmatrix} = \begin{bmatrix}
   b_1 \\
   b_2 \\
   b_3 \\
   \vdots \\
   \end{bmatrix} = \mathbf{b}
}
\eit
\end{block}
\end{frame}

% Slide
\begin{frame}{Smoothed Aggregation (SA)}
\begin{block}{Interpolation}
\bit
\item Multiple coarse-grid degrees of freedom per aggregate
\item All target vectors are in the range of interpolation
\item Smooth columns of $P$ to get improved SA interpolation
\eq{
   P\mathbf{1} = \begin{bmatrix}
   b_{1,1} & b_{2,1} & b_{3,1} & & & & &  \\
   b_{1,2} & b_{2,2} & b_{3,2} & & & & &  \\
   b_{1,3} & b_{2,3} & b_{3,3} & & & & &  \\
   & & & b_{1,4} & b_{2,4} & b_{3,4} &  \\
   & & & b_{1,5} & b_{2,5} & b_{3,5} &  \\
   & & & b_{1,6} & b_{2,6} & b_{3,6} &  \\
   & & & & \ddots & \ddots &  
   \end{bmatrix}\mathbf{1} = \mathbf{b}_1 + \mathbf{b}_2 + \mathbf{b}_3
}
\eit
\end{block}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}

